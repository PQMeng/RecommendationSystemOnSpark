{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Recommendation System Using ALS Algorithms with Saprk\n",
    "---\n",
    "\n",
    "This file will build a recommendation system on the [Movielens](https://grouplens.org/datasets/movielens/) dataset. using [Alternating Least Squares](https://spark.apache.org/docs/latest/mllib-collaborative-filtering.html) algorithms with Spark. Particularly, this file is in the early development and debugging phase, which will only use a small dataset from Movielens instead of the complete dataset, and there will also elaborate how to search parameters for ALS algorithms for later use. \n",
    "\n",
    "Key components of this file:\n",
    "* **Preparing data**. Look into the data and conclude the statistics of the data to provide evidence to select algorithms.\n",
    "* **Parameters searching using a small set of data**. Before developing a recommendation engine on the whole dataset, using a small amount of data fitting into a single machine's memory to develop and test the recommendation system and search for parameters if necessary.\n",
    "* **AWS EMR deployment** (see details in README.md file.)\n",
    "\n",
    "Since it's not a classification problem, Root Mean Square Error will be used to evaluate it's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data\n",
    "---\n",
    "\n",
    "Small dataset : 100,000 ratings and 3,600 tag applications applied to 9,000 movies by 600 users. Last updated 9/2018.\n",
    "\n",
    "The specific statistics are:\n",
    "1. ratings.csv (100837 lines) with format: \n",
    "`userId, movieId, raitng, timestamp`   Eg.(1,70,3.0,964982400)\n",
    "\n",
    "2. movies.csv (9743 lines) with format:\n",
    "`movieId, title, gengres`   Eg.(6,Heat (1995),Action|Crime|Thriller)\n",
    "\n",
    "3. tags.csv (3684 lines) with format:\n",
    "`userId, movieId, tag, timestamp`   Eg.(2,60756,funny,1445714994)\n",
    "\n",
    "4. links.csv (9743 lines) with format:\n",
    "`movieId, imdbId, tmdbId`   Eg.(1,0114709,862)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the raw data, filter the header and parse it into a new RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "sc = pyspark.SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# datasets_path = '~/where-you-data-locates'\n",
    "datasets_path = 'dataset/ml-latest-small'\n",
    "small_ratings_file = os.path.join(datasets_path, 'ratings.csv')\n",
    "small_ratings_raw_data = sc.textFile(small_ratings_file)\n",
    "small_ratings_raw_data_header = small_ratings_raw_data.take(1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering out 'timestep' bacause we don't need it so far. Using `cache()` to save it in the memory for later use because this RDD will be used frequently.\n",
    "\n",
    "**note**: You can mark an RDD to be persisted using the persist() or cache() methods on it. each persisted RDD can be stored using a different storage level The cache() method is a shorthand for using the default storage level, which is StorageLevel.MEMORY_ONLY (store deserialized objects in memory). refered from:https://stackoverflow.com/questions/26870537/what-is-the-difference-between-cache-and-persist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_ratings_data = small_ratings_raw_data.filter(lambda line: line != small_ratings_raw_data_header)\\\n",
    "            .map(lambda line: line.split(',')).map(lambda tokens: (tokens[0], tokens[1], tokens[2])).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply all the same to the movie.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_movies_file = 'dataset/ml-latest-small/movies.csv'\n",
    "\n",
    "small_movies_raw_data = sc.textFile(small_movies_file)\n",
    "small_movie_file_header = small_movies_raw_data.take(1)[0]\n",
    "\n",
    "small_movies_data = small_movies_raw_data.filter(lambda line: line!=small_movie_file_header)\\\n",
    "                .map(lambda line: line.split(',')).map(lambda tokens: (tokens[0], tokens[1])).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to determine the ALS parameters. we are going to split the dataset into training set, validation set and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_RDD, validation_RDD, test_RDD = small_ratings_data.randomSplit([6, 2, 2], seed = 0)\n",
    "validation_for_predict_RDD = validation_RDD.map(lambda x: (x[0], x[1]))\n",
    "test_for_predict_RDD = test_RDD.map(lambda x: (x[0], x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finished"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters searching using a small set of data\n",
    "---\n",
    "\n",
    "The implementation in MLlib has the following parameters:\n",
    "\n",
    "* numBlocks is the number of blocks used to parallelize computation (set to -1 to auto-configure).\n",
    "* rank is the number of latent factors in the model.\n",
    "* iterations is the number of iterations to run.\n",
    "* lambda specifies the regularization parameter in ALS.\n",
    "* implicitPrefs specifies whether to use the explicit feedback ALS variant or one adapted for implicit feedback data.\n",
    "* alpha is a parameter applicable to the implicit feedback variant of ALS that governs the baseline confidence in preference observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rank 4 the RMSE is 0.9160644755656506\n",
      "For rank 8 the RMSE is 0.9193834821092156\n",
      "For rank 12 the RMSE is 0.9179160443531135\n",
      "The best rank for the model is 4\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.recommendation import ALS\n",
    "import math\n",
    "\n",
    "# set hyper-parameters\n",
    "seed = 1\n",
    "iterations = 10\n",
    "regularization_parameter = 0.1\n",
    "ranks = [4, 8, 12]\n",
    "errors = [0, 0, 0]\n",
    "err = 0\n",
    "tolerance = 0.02\n",
    "\n",
    "min_error = float('inf')\n",
    "best_rank = -1\n",
    "best_iteratoin = -1\n",
    "\n",
    "# start training\n",
    "for rank in ranks:\n",
    "    model = ALS.train(training_RDD, rank, seed=seed, iterations=iterations, \n",
    "                     lambda_=regularization_parameter)\n",
    "    predictions = model.predictAll(validation_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "    rates_and_preds = validation_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "    # calculate the error\n",
    "    error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "    errors[err] = error\n",
    "    err += 1\n",
    "    print(\"For rank %s the RMSE is %s\"%(rank, error))\n",
    "    if error < min_error:\n",
    "        min_error = error\n",
    "        best_rank = rank\n",
    "    \n",
    "print(\"The best rank for the model is %s\"%(best_rank))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can test the selected model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For test data, the RMSE is0.9142876730094521\n"
     ]
    }
   ],
   "source": [
    "model = ALS.train(training_RDD, best_rank, seed=seed, iterations=iterations,\n",
    "                 lambda_=regularization_parameter)\n",
    "raw_predictions = model.predictAll(test_for_predict_RDD)\n",
    "# raw_predictoin is a (user, produdct, raitng) tuple\n",
    "predictions = raw_predictions.map(lambda r: ((r[0], r[1]), r[2]))\n",
    "rates_and_preds = test_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0]-r[1][1])**2).mean())\n",
    "\n",
    "print(\"For test data, the RMSE is%s\"%error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end, the ALS recommendation system was developed and teset through a small amount of dataset. Beside, we also selected the rank parameter as 4. Next, I will build the system on the complete dataset and deploy it on the AWS EMR Clusters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
